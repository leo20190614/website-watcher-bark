å®Œç¾ï¼ä½ å·²ç»æä¾›äº†ï¼š
	â€¢	âœ… Bark Keyï¼š2qRcV2zJa2NXGAH7MFmtSd
	â€¢	âœ… IFTTT Keyï¼šb15svmb9LKl10Yk-zC9AVx

æ¥ä¸‹æ¥æˆ‘ä¸ºä½ ç”Ÿæˆäº†å®Œæ•´çš„æ•´åˆç‰ˆ check_sites.py è„šæœ¬ï¼Œå®ç°å¦‚ä¸‹åŠŸèƒ½ï¼š

â¸»

âœ… åŠŸèƒ½ä¸€è§ˆ

åŠŸèƒ½	çŠ¶æ€
ç½‘ç«™ç›‘æµ‹ï¼ˆChangi, OCBC, MAS, DBS, UOBï¼‰	âœ…
è‡ªåŠ¨å»é‡ï¼Œé¿å…é‡å¤é€šçŸ¥	âœ…
Bark æ¨é€ï¼ˆiOS åŸç”Ÿï¼‰	âœ…
IFTTT æ¨é€ï¼ˆæ ¼å¼å®Œæ•´ï¼‰	âœ…
æ¯ 30 åˆ†é’Ÿè‡ªåŠ¨è¿è¡Œï¼ˆGitHub Actions å·²è®¾ç½®ï¼‰	âœ…
ä¸´æ—¶å–æ¶ˆå…³é”®è¯è¿‡æ»¤ï¼ˆæµ‹è¯•æ›´çµæ•ï¼‰	âœ…


â¸»

ğŸ“„ æœ€ç»ˆå®Œæ•´è„šæœ¬ï¼šcheck_sites.py

import requests
from bs4 import BeautifulSoup
import json
import os
from datetime import datetime

HEADERS = {"User-Agent": "Mozilla/5.0"}
BARK_KEY = "2qRcV2zJa2NXGAH7MFmtSd"
IFTTT_KEY = "b15svmb9LKl10Yk-zC9AVx"

def send_notifications(title, link):
    now = datetime.now().strftime("%Y-%m-%d %H:%M:%S")

    # Bark é€šçŸ¥
    bark_url = f"https://api.day.app/{BARK_KEY}/{title}/{link}\n{now}"
    try:
        requests.get(bark_url)
        print(f"âœ… Bark æ¨é€æˆåŠŸï¼š{title}")
    except Exception as e:
        print(f"âŒ Bark æ¨é€å¤±è´¥ï¼š{e}")

    # IFTTT é€šçŸ¥
    ifttt_url = f"https://maker.ifttt.com/trigger/website_update/json/with/key/{IFTTT_KEY}"
    payload = {
        "value1": title,
        "value2": link,
        "value3": now
    }
    try:
        requests.post(ifttt_url, json=payload)
        print(f"âœ… IFTTT æ¨é€æˆåŠŸï¼š{title}")
    except Exception as e:
        print(f"âŒ IFTTT æ¨é€å¤±è´¥ï¼š{e}")

def check_changi():
    url = "https://www.changiairport.com/en/corporate/our-media-hub/publications/reports.html"
    res = requests.get(url, headers=HEADERS, timeout=15)
    soup = BeautifulSoup(res.text, "html.parser")
    links = soup.select("a[href$='.pdf']")
    return [(link.get_text(strip=True), "https://www.changiairport.com" + link["href"]) for link in links]

def check_ocbc():
    url = "https://www.ocbc.com/group/research/index"
    res = requests.get(url, headers=HEADERS, timeout=15)
    soup = BeautifulSoup(res.text, "html.parser")
    links = soup.select("a[href$='.pdf']")
    return [(link.get_text(strip=True), "https://www.ocbc.com" + link["href"]) for link in links]

def check_mas():
    url = "https://www.mas.gov.sg/news/media-releases"
    res = requests.get(url, headers=HEADERS, timeout=15)
    soup = BeautifulSoup(res.text, "html.parser")
    items = soup.select("div.card--article__text > a")
    return [(i.get_text(strip=True), "https://www.mas.gov.sg" + i["href"]) for i in items]

def check_dbs():
    url = "https://www.dbs.com.sg/corporate/aics/at-a-glance.page"
    res = requests.get(url, headers=HEADERS, timeout=15)
    soup = BeautifulSoup(res.text, "html.parser")
    items = soup.select("div.aics-card .title a")
    return [(i.get_text(strip=True), "https://www.dbs.com.sg" + i["href"]) for i in items]

def check_uob():
    url = "https://www.uobgroup.com/research/todays-focus.page"
    res = requests.get(url, headers=HEADERS, timeout=15)
    soup = BeautifulSoup(res.text, "html.parser")
    items = soup.select("a[href$='.pdf']")
    return [(i.get_text(strip=True), "https://www.uobgroup.com" + i["href"]) for i in items]

def load_history():
    if os.path.exists("history.json"):
        with open("history.json", "r") as f:
            return json.load(f)
    return {}

def save_history(history):
    with open("history.json", "w") as f:
        json.dump(history, f)

def main():
    history = load_history()
    updated = False

    for site, func in [
        ("changi", check_changi),
        ("ocbc", check_ocbc),
        ("mas", check_mas),
        ("dbs", check_dbs),
        ("uob", check_uob)
    ]:
        if site not in history:
            history[site] = []

        for title, link in func():
            if link not in history[site]:
                # æš‚æ—¶å…³é—­å…³é”®è¯è¿‡æ»¤ï¼Œæ¨é€å…¨éƒ¨æ–°å†…å®¹
                send_notifications(f"{site.upper()} æœ‰æ–°å†…å®¹", f"{title}\n{link}")
                history[site].append(link)
                updated = True

    if updated:
        save_history(history)

if __name__ == "__main__":
    main()


â¸»

âœ… ä¸Šä¼ æ­¥éª¤æç¤º
	1.	æ‰“å¼€ GitHub ä»“åº“ website-watcher-bark
	2.	æ‰¾åˆ°å¹¶ç¼–è¾‘ check_sites.py
	3.	å°†å†…å®¹æ›¿æ¢ä¸ºä¸Šè¿°å…¨éƒ¨å†…å®¹
	4.	history.json ä¿æŒä¸ºç©º {}ï¼ˆé¦–æ¬¡æ¨é€ä¸ä¼šè·³è¿‡ï¼‰
	5.	ç„¶åç‚¹å‡» Actions â†’ Run workflow æ‰‹åŠ¨è¿è¡Œæµ‹è¯•ä¸€æ¬¡

â¸»

ğŸ§ª æµ‹è¯•åä½ åº”å½“æ”¶åˆ°ä¸¤ä¸ªé€šçŸ¥ï¼š

æ¥æº	å†…å®¹
Bark	åŸç”Ÿé€šçŸ¥ï¼Œæ˜¾ç¤ºç½‘ç«™å + æŠ¥å‘Šæ ‡é¢˜
IFTTT	æ¨¡æ¿æ ¼å¼é€šçŸ¥ï¼ˆæ ‡é¢˜ã€é“¾æ¥ã€æ—¶é—´ï¼‰


â¸»

å¦‚æœä½ å¸Œæœ›ç»§ç»­æ·»åŠ è”åˆæ—©æŠ¥ã€Telegram æ¨é€ã€ç¿»è¯‘æ”¯æŒã€HTML ç½‘é¡µè¾“å‡ºç­‰ï¼Œåªéœ€è¯´ä¸€å¥ï¼š

â€œç»§ç»­ + åŠŸèƒ½åâ€
æˆ‘å¯ä»¥ç»§ç»­å‡çº§ç³»ç»Ÿä¸ºä½ å®šåˆ¶ã€‚ç°åœ¨æµ‹è¯•å§ï¼æ˜¯å¦æ”¶åˆ°åŒé€šçŸ¥ï¼Ÿ
